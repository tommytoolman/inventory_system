"""
Imports data from a specific Vintage & Rare CSV file format using pandas. 
It creates Product and PlatformListing records. 
Potential Cleanup: This seems specific to a one-off CSV import task. 
If the main import_vr.py (which scrapes directly) is the primary method now, this script might be redundant or only kept for historical reference/example. 
It also notably uses synchronous SQLAlchemy.
"""
import click
import pandas as pd
from sqlalchemy import create_engine
from sqlalchemy.orm import Session
import sys
import logging
from pathlib import Path
from datetime import datetime, timezone
import re
from app.models.product import Product, PlatformListing, CSVImportLog
from app.database import Base
from app.core.config import get_settings

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def setup_database():
    """Create database connection."""
    settings = get_settings()
    # Convert asyncpg to psycopg for synchronous operations
    db_url = settings.DATABASE_URL.replace('+asyncpg', '')
    engine = create_engine(db_url)
    return engine

def extract_number(value):
    """Extract the first number from a string."""
    if pd.isna(value):
        return None
    if isinstance(value, (int, float)):
        return int(value)
    # Extract first number from string
    match = re.search(r'\d+', str(value))
    return int(match.group()) if match else None

def clean_boolean(value):
    """Convert various boolean-like values to True/False."""
    if pd.isna(value):
        return False
    if isinstance(value, bool):
        return value
    return str(value).lower().strip() in ['true', 'yes', '1', 'y', 't']

@click.command()
@click.argument('csv_file', type=click.Path(exists=True))
@click.option('--dry-run', is_flag=True, help='Show what would be imported without making changes')
def import_vintage_data(csv_file, dry_run):
    """Import initial data from VintageAndRare CSV file."""
    try:
        logger.info(f"Starting import from {csv_file}")
        engine = setup_database()
        
        # Read CSV file
        df = pd.read_csv(csv_file)
        logger.info(f"Found {len(df)} rows in CSV")

        if dry_run:
            logger.info("DRY RUN - No changes will be made")
            
        with Session(engine) as session:
            successful = 0
            platform_listings_created = 0
            errors = []
            
            # Process each row
            for index, row in df.iterrows():
                try:
                    # Convert row to product data
                    product_data = {
                        'brand': str(row['brand name']) if pd.notna(row['brand name']) else None,
                        'category': str(row['category name']) if pd.notna(row['category name']) else None,
                        'product': str(row['product model name']) if pd.notna(row['product model name']) else None,
                        'year': int(row['product year']) if pd.notna(row['product year']) else None,
                        'decade': int(row['decade']) if pd.notna(row['decade']) else None,
                        'finish': str(row['product finish']) if pd.notna(row['product finish']) else None,
                        'description': str(row['product description']) if pd.notna(row['product description']) else None,
                        'price': float(row['product price']) if pd.notna(row['product price']) else 0.0,
                        'price_notax': float(row['product price notax']) if pd.notna(row['product price notax']) else None,
                        'is_sold': clean_boolean(row['product sold']),
                        'in_collective': clean_boolean(row['product in collective']),
                        'in_inventory': clean_boolean(row['product in inventory']),
                        'in_reseller': clean_boolean(row['product in reseller']),
                        'collective_discount': float(row['collective discount']) if pd.notna(row['collective discount']) else None,
                        'free_shipping': clean_boolean(row['free shipping']),
                        'buy_now': clean_boolean(row['buy now']),
                        'show_vat': clean_boolean(row['show vat']),
                        'local_pickup': clean_boolean(row['local pickup']),
                        'available_for_shipment': clean_boolean(row['available for shipment']),
                        'processing_time': extract_number(row['processing time']),
                        'image_url': str(row['image url']) if pd.notna(row['image url']) else None,
                        'video_url': str(row['video url']) if pd.notna(row['video url']) else None,
                        'external_link': str(row['external link']) if pd.notna(row['external link']) else None,
                    }

                    if not dry_run:
                        # Create product
                        product = Product(**product_data)
                        session.add(product)
                        session.flush()  # Get the product ID

                        # Create VintageAndRare platform listing with generated ID
                        platform_listing = PlatformListing(
                            platform_name='vintageandrare',
                            external_id=f"VR-{product.id}",  # Generate consistent external ID
                            product_id=product.id,
                            sync_status='imported',
                            last_sync=datetime.now(timezone.utc)()
                        )
                        session.add(platform_listing)
                        platform_listings_created += 1

                    successful += 1
                    if index % 100 == 0:
                        logger.info(f"Processed {index + 1} rows...")

                except Exception as e:
                    error_msg = f"Error processing row {index}: {str(e)}"
                    logger.error(error_msg)
                    errors.append(error_msg)

            if not dry_run:
                # Create import log
                import_log = CSVImportLog(
                    filename=Path(csv_file).name,
                    platform='vintageandrare',
                    total_rows=len(df),
                    successful_rows=successful,
                    failed_rows=len(errors),
                    error_log={'errors': errors}
                )
                session.add(import_log)
                
                # Commit all changes
                session.commit()
                logger.info(f"Successfully imported {successful} products")
                logger.info(f"Created {platform_listings_created} platform listings")
                if errors:
                    logger.warning(f"Encountered {len(errors)} errors during import")
            else:
                logger.info(f"DRY RUN - Would have imported {successful} products")
                logger.info(f"DRY RUN - Would have created {platform_listings_created} platform listings")
                if errors:
                    logger.warning(f"DRY RUN - Would have encountered {len(errors)} errors")

    except Exception as e:
        logger.error(f"Fatal error during import: {str(e)}")
        sys.exit(1)

if __name__ == '__main__':
    import_vintage_data()